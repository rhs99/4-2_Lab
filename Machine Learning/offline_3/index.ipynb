{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "alpha = 0.01\n",
    "itr_limit = 100\n",
    "\n",
    "dbg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "z = wx + b\n",
    "\"\"\"\n",
    "class FullyConnected:\n",
    "    def __init__(self, out_dim):\n",
    "        self.out_dim = out_dim\n",
    "        self.a = None\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.z = None\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, a):\n",
    "        if self.w is None or self.b is None:\n",
    "            self.w = np.random.random((self.out_dim, a.shape[0]))*0.01\n",
    "            self.b = np.zeros((self.out_dim, 1))\n",
    "\n",
    "        self.a = a\n",
    "        self.z = np.dot(self.w, a) + self.b\n",
    "\n",
    "        if dbg:\n",
    "            print(\"fc_forward: \")\n",
    "            print(self.z.shape)\n",
    "\n",
    "        return self.z\n",
    "\n",
    "    def backward(self, dz):\n",
    "        m = dz.shape[1]\n",
    "        self.dw = np.matmul(dz, self.a.T)/m\n",
    "        self.db = np.sum(dz, axis=1, keepdims=True)/m\n",
    "        self.w = self.w - alpha*self.dw\n",
    "        self.b = self.b - alpha*self.db\n",
    "        da = np.matmul(self.w.T, dz)\n",
    "        return da\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "a = ReLU(z)\n",
    "\"\"\"\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.out_dim = None\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(z):\n",
    "        r = np.maximum(0, z)\n",
    "        return r\n",
    "\n",
    "    @staticmethod\n",
    "    def relu_derivative(z):\n",
    "        dz = np.array(z, copy=True)\n",
    "        dz[dz<=0] = 0\n",
    "        dz[dz>0] = 1\n",
    "        return dz\n",
    "\n",
    "    def forward(self, z):\n",
    "        if self.out_dim is None:\n",
    "            self.out_dim = z.shape[0]\n",
    "        self.z = z\n",
    "        self.a = self.relu(z)\n",
    "        if dbg:\n",
    "            print(\"relu_forward: \")\n",
    "            print(self.a.shape)\n",
    "        return self.a\n",
    "\n",
    "    def backward(self, da):\n",
    "        dz = np.multiply(da, self.relu_derivative(self.z))\n",
    "        return dz\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    m = y.shape[1]\n",
    "    logs = np.multiply(np.log(y_hat),y)\n",
    "    cost = - np.sum(logs) / m\n",
    "    return cost\n",
    "\n",
    "\"\"\"\n",
    "y_hat = e^z/sum(e^x)\n",
    "\"\"\"\n",
    "class SoftMax:\n",
    "    def __init__(self):\n",
    "        self.out_dim = None\n",
    "        self.z = None\n",
    "        self.y_hat = None\n",
    "\n",
    "    def forward(self, z):\n",
    "        if self.out_dim is None:\n",
    "            self.out_dim = z.shape[0]\n",
    "        self.z = z\n",
    "        self.y_hat = np.exp(z) / np.sum(np.exp(z), axis=0)\n",
    "        if dbg:\n",
    "            print(\"soft_forward: \")\n",
    "            print(self.y_hat.shape)\n",
    "        return self.y_hat\n",
    "\n",
    "    def backward(self, y):\n",
    "        dz = self.y_hat - y\n",
    "        return dz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    df = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
    "    num_features = df.shape[1] - 1\n",
    "    df = pd.get_dummies(df, columns=[4], drop_first=False)\n",
    "    train_dataset = df.to_numpy()\n",
    "    x_train = train_dataset[:,:num_features]\n",
    "    y_train = train_dataset[:,num_features:]\n",
    "\n",
    "    x_train = x_train.T\n",
    "    y_train = y_train.T\n",
    "\n",
    "    # print(x_train.shape)\n",
    "    # print(y_train.shape)\n",
    "    return x_train, y_train\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "def modify_level(y_hat):\n",
    "    for j in range(y_hat.shape[1]):\n",
    "        mx = -10\n",
    "        mx_idx = -1\n",
    "        for i in range(y_hat.shape[0]):\n",
    "            if y_hat[i,j] > mx:\n",
    "                mx = y_hat[i,j]\n",
    "                mx_idx = i\n",
    "            y_hat[i][j] = 0\n",
    "        y_hat[mx_idx, j] = 1\n",
    "\n",
    "    return y_hat\n",
    "\n",
    "def calc_accuracy(y_hat, y):\n",
    "    match = 0\n",
    "    for j in range(y_hat.shape[1]):\n",
    "        flag = 0\n",
    "        for i in range(y_hat.shape[0]):\n",
    "            if y_hat[i,j] != y[i,j]:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            match += 1\n",
    "\n",
    "    print(\"accuracy: \" + str(match/y_hat.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_cnn():\n",
    "    f1 = open(\"architecture.txt\", \"r\")\n",
    "    lines = f1.readlines()\n",
    "    cnn_layers = list()\n",
    "    for line in lines:\n",
    "        words = line.strip().split()\n",
    "        if words[0].lower() == \"fc\":\n",
    "            cnn_layers.append(FullyConnected(int(words[1])))\n",
    "        elif words[0].lower() == \"relu\":\n",
    "            cnn_layers.append(ReLU())\n",
    "        elif words[0].lower() == \"softmax\":\n",
    "            cnn_layers.append(SoftMax())\n",
    "\n",
    "    f1.close()\n",
    "\n",
    "    x, y = read_data(\"Toy Dataset/trainNN.txt\")\n",
    "\n",
    "    for itr in range(itr_limit):\n",
    "        prev_a = x\n",
    "        for layer in cnn_layers:\n",
    "            prev_a = layer.forward(prev_a)\n",
    "\n",
    "        prev_derivative = y\n",
    "        for i in range(len(cnn_layers)-1,0,-1):\n",
    "            prev_derivative = cnn_layers[i].backward(prev_derivative)\n",
    "\n",
    "        # if itr % 500 == 0:\n",
    "        #     print(cross_entropy(prev_a, y))\n",
    "\n",
    "    # prev_a = modify_level(prev_a)\n",
    "    # calc_accuracy(prev_a, y)\n",
    "\n",
    "    x_test, y_test = read_data(\"Toy Dataset/testNN.txt\")\n",
    "\n",
    "    prev_a = x_test\n",
    "    for itr in range(itr_limit):\n",
    "        prev_a = x\n",
    "        for layer in cnn_layers:\n",
    "            prev_a = layer.forward(prev_a)\n",
    "\n",
    "    prev_a = modify_level(prev_a)\n",
    "    calc_accuracy(prev_a, y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.256\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "run cnn\n",
    "\"\"\"\n",
    "run_cnn()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}